{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Practice 02: Dealing with texts using CNN\n",
    "\n",
    "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/logos/front_page.png\" width=400px>\n",
    "\n",
    "Based on YSDA [materials](https://github.com/yandexdataschool/nlp_course/blob/master/week02_classification/seminar.ipynb). _Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34x92vWQycN_"
   },
   "source": [
    "### About the challenge\n",
    "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0). \n",
    "\n",
    "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  119M  100  119M    0     0  15.6M      0  0:00:07  0:00:07 --:--:-- 19.4M\n",
      "Train_rev1.csv\n"
     ]
    }
   ],
   "source": [
    "# Do this only once\n",
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7kznuJfycOH"
   },
   "source": [
    "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
    "\n",
    "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
    "\n",
    "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fcu-qmHRycOK"
   },
   "source": [
    "Our task is to predict one number, __Log1pSalary__.\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "p9vyA_erycOK",
    "outputId": "af9a21f3-10b7-4fde-d4cd-1f66939566b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140343</th>\n",
       "      <td>70575500</td>\n",
       "      <td>Service Advisor, East Cheshire, Motor Trade Job</td>\n",
       "      <td>Automotive, Motor Trade Job: Experienced Servi...</td>\n",
       "      <td>Alderley Edge</td>\n",
       "      <td>Alderley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Perfect Placement</td>\n",
       "      <td>Trade &amp; Construction Jobs</td>\n",
       "      <td>20000 per annum + OTE 40,000</td>\n",
       "      <td>30000</td>\n",
       "      <td>MyUkJobs</td>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149748</th>\n",
       "      <td>70763776</td>\n",
       "      <td>Dentist</td>\n",
       "      <td>Dentist Jobs in York, North Yorkshire. Zest De...</td>\n",
       "      <td>York, North Yorkshire</td>\n",
       "      <td>York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Zest Business Group</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>66000 - 85000/annum</td>\n",
       "      <td>75500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>11.231901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115900</th>\n",
       "      <td>69776064</td>\n",
       "      <td>CNC Lathe programmer setter operator</td>\n",
       "      <td>My Client, based in Coventry, due to increased...</td>\n",
       "      <td>Coventry, West Midlands</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Kinetic PLC</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>24000 - 27000/annum OT</td>\n",
       "      <td>25500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.146473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                            Title  \\\n",
       "140343  70575500  Service Advisor, East Cheshire, Motor Trade Job   \n",
       "149748  70763776                                          Dentist   \n",
       "115900  69776064             CNC Lathe programmer setter operator   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "140343  Automotive, Motor Trade Job: Experienced Servi...   \n",
       "149748  Dentist Jobs in York, North Yorkshire. Zest De...   \n",
       "115900  My Client, based in Coventry, due to increased...   \n",
       "\n",
       "                    LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "140343            Alderley Edge           Alderley          NaN          NaN   \n",
       "149748    York, North Yorkshire               York          NaN    permanent   \n",
       "115900  Coventry, West Midlands           Coventry          NaN    permanent   \n",
       "\n",
       "                    Company                   Category  \\\n",
       "140343    Perfect Placement  Trade & Construction Jobs   \n",
       "149748  Zest Business Group  Healthcare & Nursing Jobs   \n",
       "115900          Kinetic PLC           Engineering Jobs   \n",
       "\n",
       "                           SalaryRaw  SalaryNormalized        SourceName  \\\n",
       "140343  20000 per annum + OTE 40,000             30000          MyUkJobs   \n",
       "149748           66000 - 85000/annum             75500  cv-library.co.uk   \n",
       "115900        24000 - 27000/annum OT             25500  cv-library.co.uk   \n",
       "\n",
       "        Log1pSalary  \n",
       "140343    10.308986  \n",
       "149748    11.231901  \n",
       "115900    10.146473  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUdclucmycON"
   },
   "source": [
    "### Preprocessing text data\n",
    "\n",
    "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
    "\n",
    "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "YzeOxD_aycOO",
    "outputId": "b4826117-1196-4a0e-92fa-6fd3ca609202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    # <YOUR CODE HERE>\n",
    "    text = str(text).lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3pQdHihycOT"
   },
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Gs-6lnS_ycOU",
    "outputId": "8948250d-7117-4e4f-a38d-00405f9b2cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouE3L2hyycOX"
   },
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iC7hBwwjycOX",
    "outputId": "70eb75fc-535f-45a3-ad97-95a98e1d020f"
   },
   "outputs": [],
   "source": [
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter() # <YOUR CODE HERE>\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title', 'FullDescription']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28465it [00:20, 9796.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 126 ms, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _, row in data[text_columns].iterrows():\n",
    "    for text in row:\n",
    "        token_counts.update(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.66 s, sys: 104 ms, total: 9.77 s\n",
      "Wall time: 9.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "token_counts2 = Counter() # <YOUR CODE HERE>\n",
    "for row in data[text_columns].values.flatten():\n",
    "    token_counts2.update(row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = token_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "nd5v3BNfycOf",
    "outputId": "1c59b386-f052-4340-bf5d-09ae8d15983c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znuXxeghycOh"
   },
   "source": [
    "Now filter tokens a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeNFBWx5ycOh"
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, counts in token_counts.items() if counts >= min_count] # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RATIRyPKycOk",
    "outputId": "6bb7482c-7c46-4f7e-81f2-6b70e04abc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "del simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqEsgbjZycOo"
   },
   "source": [
    "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L60lo1l_ycOq"
   },
   "outputs": [],
   "source": [
    "# You have already done that ;)\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)} # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DeAoVo4mycOr",
    "outputId": "8f29ef68-f9bd-4628-8222-1dc17f8f2590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmJAkq3gycOv"
   },
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGOdZ3-dycO4"
   },
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[27645, 29893, 33674,     1,     1,     1,     1],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
       "        [10609, 30412, 17746,    33,  8705, 29157,    65]], dtype=int32),\n",
       " 'FullDescription': array([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451,\n",
       "         32939],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,\n",
       "            82],\n",
       "        [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412,\n",
       "         17746]], dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'Log1pSalary': array([ 9.71154 , 10.463132, 10.71444 ], dtype=float32)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens = len(tokens)\n",
    "n_cat_features = len(categorical_vectorizer.vocabulary_)\n",
    "hid_size = 64\n",
    "n_maximums = 2\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "# <YOUR CODE HERE>\n",
    "\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size*2,\n",
    "    kernel_size=2\n",
    "))\n",
    "\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "\n",
    "simple_model.add_module('conv2', nn.Conv1d(\n",
    "    in_channels=hid_size*2,\n",
    "    out_channels=hid_size*2,\n",
    "    kernel_size=3\n",
    "))\n",
    "\n",
    "simple_model.add_module('bn1', nn.BatchNorm1d(hid_size*2))\n",
    "simple_model.add_module('relu2', nn.ReLU())\n",
    "\n",
    "simple_model.add_module('adaptive_pool', nn.AdaptiveMaxPool1d(n_maximums))\n",
    "simple_model.add_module('flatten', nn.Flatten())\n",
    "simple_model.add_module('out', nn.Linear(hid_size*2*n_maximums, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 309])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-5ad72cf5a482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FullDescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "input_tensor = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "out = simple_model(input_tensor)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without the reorder operation\n",
    "# batch_size, seq_len, n_features\n",
    "# equal to \n",
    "# N, L, C_{\\text{in}}\n",
    "# and we want\n",
    "# (N, C_{\\text{in}}, L)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (emb): Embedding(34158, 64)\n",
       "  (reorder): Reorder()\n",
       "  (conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (adaptive_pool): AdaptiveMaxPool1d(output_size=2)\n",
       "  (flatten): Flatten()\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "b += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 3.])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = simple_model\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss() # <YOUR CODE HERE>\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
    "        target = torch.tensor(target).to(device)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target) # <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        # <YOUR CODE HERE>\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.item())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (emb): Embedding(34158, 64)\n",
       "  (reorder): Reorder()\n",
       "  (conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (adaptive_pool): AdaptiveMaxPool1d(output_size=2)\n",
       "  (flatten): Flatten()\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-165-c500e77a6287>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_x, batch_y in tqdm_notebook(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4534d7f5c29248b493e0f1feb5aa40ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "56it [00:17, 19.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train results:\n",
      "Mean square error: 0.21913\n",
      "Mean absolute error: 0.36101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5380a8eeecfc451b9da892507211acae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val results:\n",
      "Mean square error: 0.22043\n",
      "Mean absolute error: 0.36108\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in tqdm_notebook(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
    "        batch_pred = simple_model(batch)[:, 0].detach().cpu().numpy()\n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(simple_model, data_train, name='Train')\n",
    "print_metrics(simple_model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-166-52414358e350>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_x, batch_y in tqdm_notebook(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce52f71c37ce4624ae47289bc5f2c521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train results:\n",
      "Mean square error: 257372688.21653\n",
      "Mean absolute error: 12007.56250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2139dd212b5421fa99e461ab1c2ae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val results:\n",
      "Mean square error: 257536427.84851\n",
      "Mean absolute error: 12002.46136\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in tqdm_notebook(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
    "        batch_pred = simple_model(batch)[:, 0].detach().cpu().numpy()\n",
    "        squared_error += np.sum(np.square(np.exp(batch_pred) - np.exp(batch_y)))\n",
    "        abs_error += np.sum(np.abs(np.exp(batch_pred) - np.exp(batch_y)))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(simple_model, data_train, name='Train')\n",
    "print_metrics(simple_model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus area: three-headed network.\n",
    "\n",
    "Now you can try to implement the network we've discussed above. Use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeInputsNet(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "        super(TwoInputsNet, self).__init__()\n",
    "        self.title_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        # <YOUR CODE HERE>        \n",
    "        \n",
    "        self.full_emb = nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size)\n",
    "        # <YOUR CODE HERE>\n",
    "        \n",
    "        self.category_out = # <YOUR CODE HERE>\n",
    "        \n",
    "\n",
    "    def forward(self, whole_input):\n",
    "        input1, input2, input3 = whole_input\n",
    "        title_beg = self.title_emb(input1).permute((0, 2, 1))\n",
    "        title = # <YOUR CODE HERE>\n",
    "        \n",
    "        full_beg = self.full_emb(input2).permute((0, 2, 1))\n",
    "        full = # <YOUR CODE HERE>        \n",
    "        \n",
    "        category = # <YOUR CODE HERE>        \n",
    "        \n",
    "        concatenated = torch.cat(\n",
    "            [\n",
    "            title.view(title.size(0), -1),\n",
    "            full.view(full.size(0), -1),\n",
    "            category.view(category.size(0), -1)\n",
    "            ],\n",
    "            dim=1)\n",
    "        \n",
    "        out = # <YOUR CODE HERE>\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus area 2: comparing RNN to CNN\n",
    "Try implementing simple RNN (or LSTM) and applying it to this task. Compare the quality/performance of these networks. \n",
    "*Hint: try to build networks with ~same number of paremeters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus area 3: fixing the data leaks\n",
    "Fix the data leak we ignored in the beginning of the __Deep Learning part__. Compare results with and without data leaks using same architectures and training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "week04_practice_CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "py3_research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
